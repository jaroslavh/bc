6. 11. 2018
Prepared dataset for testing basic cluster representation algorithms. It has 3
clusters of different size and density (1000, 1200 and 800 points). These
clusters do not overlap, however 2 are very close, almost touching.

From this dataset I prepared 5 sets for learning and testing. Always usint 80%
of the dataset to "learn" the structure of cluster and then I will try to
assign the remaining 20% to a cluster based on closest neighbor algorithm.

I was able to create representation using randomPoint and greedyApproach. I
found out that previously implemented smartGreedyApproach is not working as I
expected. I tried to fix but did not succeed yet. I will need to finish this
later.

7. 11. 2018
Fixed the smartGreedyApproach algorighm. Had to delete the method for faster
usage and read the data from set multiple times. That approach however still
works better than I thought.

Also gave a bit of thought to kNN algorithm.
kNearestNeighbors(point, representation_file, neightbor_number).

Application is also getting a lot bigger so I need to think about getting it a
better structure. Loading from files and writing to them should be done by a
separate class.

12. 11. 2018
In the morning tried to change the structure of the project to be able to
write the kNN algorithm. I sunk deep into writing some unit tests etc, which
I thought would take a lot less time. kNN is not yet implemented, however I
improved a lot in understanding python classes.

Having a lot of problems with instances of classes. I do not know how to use
temporary instances and then to empty them. That is a lot different from C.
Just setting it to None is not enough.

15. 11. 2018
Studied a bit about python and decided to change the structre of Cluster and
Point classes. I just hope that it will bring desired results and I am not just
wasting time with it.

Also added argparse dependency to work better with arguments. Tested it on
plot-data-3d.py so far.

No progress on testing the clustering results.

19. 11. 2018
Implemented methods __eq__ for Point and Cluster methods. Also added tests for
them. For Cluster comparison there will probably be a need to implement another
__eq__ method to compare just the points without id.

Loading file finally improved. Now I can also load points of different sizes in
coordinates. I can move on to updating other files and then I can finally
implement that point_classification and tests with it.

In the end started working on changing the finding_medoids.py file to newer
structure. Tommorow I have to start working on changing the methods to work on
a whole cluster. Around line 25.

20. 11. 2018
I have rewritten all 3 so far implemented algorithms to work for whole
clusters. I need to figure out how to test them in different spaces then 3D
because the tests are not really showing any promise so far. I also need to
check one last time the greedy algorithms if they are implemented right.

I really need to move to the kNN algorithm so that I can measure some results.
I hope tommorow is the day.

I feel a bit down, because I thought that it will go much faster. However I 
should be at the end of the first refactoring period so the progress should
become faster now.

21. 11. 2018
Found a mistake in smartGreedyApproach and fixed it. Now it works as expected
finally.

I also tested a tutorial on using kNN from scikit learn using pandas. If I did 
just think of using pandas before, it would have made my job much easier. I do
not regret much though. Learned a lot.

22. 11. 2018
Ran first tests on the learn1, test1 csv suite. Here are the results. I was
using kNN algorithm with k = 5

Random:
[[200   0   0]
 [  0 236   4]
 [  0   0 160]]
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       200
           3       1.00      0.98      0.99       240
           6       0.98      1.00      0.99       160

   micro avg       0.99      0.99      0.99       600
   macro avg       0.99      0.99      0.99       600
weighted avg       0.99      0.99      0.99       600

Greedy:
[[195   1   4]
 [  5 235   0]
 [  0   0 160]]
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       200
           3       1.00      0.98      0.99       240
           6       0.98      1.00      0.99       160

   micro avg       0.98      0.98      0.98       600
   macro avg       0.98      0.98      0.98       600
weighted avg       0.98      0.98      0.98       600

Smart:
[[192   0   8]
 [  7 233   0]
 [  0   0 160]]
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       200
           3       1.00      0.97      0.99       240
           6       0.95      1.00      0.98       160

   micro avg       0.97      0.97      0.97       600
   macro avg       0.97      0.98      0.97       600
weighted avg       0.98      0.97      0.98       600

The first results are surprising, since the random selection looks to work the
best. However I need to test it on all 5 suites and also on different datasets
since these are very basic.

26. 11. 2018
After a few days working on my coding skills elsewhere I am trying to
formulate my task properly so that I can dive deeper into it.

TASK:
Given a cluster of points in a high dimensional (50+ dimensions) space that has
only one metric between points possible figure out the best way to find medoids
of given cluster. Medoids are points from that cluster that can represent the 
cluster for kNN purposes and take up less space.

Test differend medoid finding algorithms by using kNN to sort new points into 
previously represented clusters.

The metrics that I focus on are:
    1) Accuracy in assigning the points in represented clusters
    2) Points representing given cluster - the less the better for kNN and 
       other computations
    3) Speed and memory needs of the given algorithm.
    
I am not really sure if k-Medoids algorithm will work for me, because of the
cost associated with it, however I am working on it.

28. 11. 2018
Worked on determining whether the results are as expected and found out a great
bug in whole concept. While iterating through list I was deleting from it the
wrong way, which destroyed the whole concept greatly. I need to use list
comprehensions, which I finally grasped the right way. Will continue fixing it
tommorow.

29. 11. 2018
Fixed all the medoid finding algorithms to work well. The results are finally
looking better.

Created all the new results and they look great, finally it seems to be
working. I hope that now I will be able to take it to the next level with some
real data.