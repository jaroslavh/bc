{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np                                                                                                 \n",
    "import matplotlib.pyplot as plt                                                                                    \n",
    "import pandas as pd\n",
    "\n",
    "import bc_utils as butils\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from sklearn.model_selection import train_test_split                                                               \n",
    "from sklearn.preprocessing import StandardScaler                                                                   \n",
    "from sklearn.neighbors import KNeighborsClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read dataset to pandas dataframe\n",
    "# current datasets ready for testing:\n",
    "#   blobs.csv\n",
    "#   blobs_3d.csv\n",
    "#   iris.csv\n",
    "#   mfeat-mor.csv\n",
    "#   mfeat-zer.csv\n",
    "#   mfeat-pix.csv\n",
    "#   mfeat-fac.csv\n",
    "#   mfeat-fou.csv\n",
    "#   mfeat-kar.csv\n",
    "#   noisy_circles.csv\n",
    "#   noisy_circles_3d.csv\n",
    "#   overlap.csv\n",
    "#   pendigit.csv\n",
    "\n",
    "df = pd.read_csv(\"data/pendigit.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plot data\n",
    "\n",
    "Visualize data if they have 2 or 3 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('cluster')\n",
    "for group in grouped:\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = {0:'red', 1:'blue', 2:'green'}\n",
    "\n",
    "if (df.columns.size == 3):\n",
    "    fix, ax = plt.subplots()\n",
    "    grouped = df.groupby('cluster')\n",
    "    \n",
    "    i = 0\n",
    "    for key, group in grouped:\n",
    "        group.plot(ax=ax, kind='scatter', x='x', y='y',\n",
    "                   label=key, color=colors[i])\n",
    "        i = i + 1\n",
    "    plt.show()\n",
    "elif (df.columns.size == 4):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    grouped = df.groupby('cluster')\n",
    "\n",
    "    i = 0\n",
    "    for key, group in grouped:\n",
    "        ax.scatter(group['x'], group['y'], group['z'], color=colors[i])\n",
    "        i = i + 1\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"There is no good visualisation for this dataset - \" + str(df.columns.size) + \" features.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating test datasets for iris\n",
    "names = set(df['cluster'])\n",
    "\n",
    "dataframes = {}\n",
    "for name in names:\n",
    "    tmp_df = df[df['cluster'] == name]\n",
    "    dataframes[name] = butils.TestDf(tmp_df)\n",
    "    \n",
    "full_test_df = pd.DataFrame()\n",
    "for name in names:\n",
    "    full_test_df = full_test_df.append(dataframes[name].test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using delta_medoids_full algorithm\n",
    "results = {}\n",
    "res_len = []\n",
    "for name in names:\n",
    "    delta_df = dataframes[name].train_df.iloc[:, :-1]\n",
    "\n",
    "    result = butils.delta_medoids_full(delta_df, butils.estimate_delta(delta_df, distance.euclidean) , distance.euclidean)\n",
    "    result['cluster'] = name\n",
    "    results[name] = result\n",
    "    res_len.append(result.shape[0])\n",
    "\n",
    "print(res_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using delta_medoids_one_shot algorithm\n",
    "results2 = {}\n",
    "res_2_len = []\n",
    "for name in names:\n",
    "    delta_df = dataframes[name].train_df.iloc[:, :-1]\n",
    "    result = butils.delta_medoids_one_shot(delta_df, butils.estimate_delta(delta_df, distance.euclidean), distance.euclidean)\n",
    "    result['cluster'] = name\n",
    "    results2[name] = result\n",
    "    res_2_len.append(result.shape[0])\n",
    "print(res_2_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using random select algorithm #TODO use same numbers as the best method found\n",
    "results3 = {}\n",
    "res_3_len = []\n",
    "for name, len_num in zip(names, res_len):\n",
    "    delta_df = dataframes[name].train_df.iloc[:, :-1]\n",
    "    result = butils.random_select(delta_df, len_num)\n",
    "    result['cluster'] = name\n",
    "    results3[name] = result\n",
    "    res_3_len.append(result.shape[0])\n",
    "print(res_3_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using greedy algorithm\n",
    "results4 = {}\n",
    "res_4_len = []\n",
    "for name in names:\n",
    "    delta_df = dataframes[name].train_df.iloc[:, :-1]\n",
    "    result = butils.greedy_select(delta_df, butils.estimate_delta(delta_df, distance.euclidean), distance.euclidean)\n",
    "    result['cluster'] = name\n",
    "    results4[name] = result\n",
    "    res_4_len.append(result.shape[0])\n",
    "print(res_4_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training DataFrames for comparing oneshot and full delta medoids algorithm\n",
    "train_delta_medoids_full = pd.DataFrame()\n",
    "train_delta_medoids_one_shot = pd.DataFrame()\n",
    "train_random_selection = pd.DataFrame()\n",
    "train_greedy_select = pd.DataFrame()\n",
    "\n",
    "for name in names:\n",
    "    train_delta_medoids_full = train_delta_medoids_full.append(results[name])\n",
    "    train_delta_medoids_one_shot = train_delta_medoids_one_shot.append(results2[name])\n",
    "    train_random_selection = train_random_selection.append(results3[name])\n",
    "    train_greedy_select = train_greedy_select.append(results4[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPoints(ref_df, test_df):\n",
    "\n",
    "    X_train = ref_df.iloc[:, :-1].values\n",
    "    y_train = ref_df.iloc[:, -1].values\n",
    "    X_test = test_df.iloc[:, :-1].values\n",
    "    y_test = test_df.iloc[:, -1].values\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler  \n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)  \n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier  \n",
    "    classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(conf_mat)  \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_full = classifyPoints(train_delta_medoids_full, full_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matrix_one_shot = classifyPoints(train_delta_medoids_one_shot, full_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_random_selection = classifyPoints(train_random_selection, full_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_greedy_select = classifyPoints(train_greedy_select, full_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def benchmark_result_plots(matrices, titles, headers):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "    matrices - list of 2d np.array\n",
    "    titles - list of graph titles\n",
    "    names - list of labels\n",
    "    \"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(15,15))\n",
    "    ax_list = [ax1, ax2, ax3, ax4]\n",
    "\n",
    "    for index in range(0, len(matrices)):\n",
    "        tick_labels = sorted(list(headers[index]))\n",
    "        ax = ax_list[index]\n",
    "        ax.imshow(matrices[index], cmap='binary')\n",
    "\n",
    "        # We want to show all ticks...\n",
    "        ax.set_xticks(np.arange(len(tick_labels)))\n",
    "        ax.set_yticks(np.arange(len(tick_labels)))\n",
    "\n",
    "        # ... and label them with the respective list entries\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "\n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax.get_xticklabels(), ha=\"right\")\n",
    "\n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        for i in range(len(tick_labels)):\n",
    "            for j in range(len(tick_labels)):\n",
    "                if(matrices[index][i, j] == 0):\n",
    "                    continue\n",
    "                if i == j:\n",
    "                    text = ax.text(j, i, matrices[index][i, j], ha=\"center\", va=\"center\", color=\"g\",\n",
    "                                   weight=\"bold\", fontsize=16)\n",
    "                    continue\n",
    "                else:\n",
    "                    text = ax.text(j, i, matrices[index][i, j], ha=\"center\", va=\"center\", color = \"r\",\n",
    "                                   weight=\"bold\", fontsize=16)\n",
    "            \n",
    "        ax.set_title(titles[index], fontsize=16)\n",
    "        \n",
    "benchmark_result_plots([matrix_full, matrix_one_shot, matrix_random_selection, matrix_greedy_select],\n",
    "                       ['Delta-Medoids Full', 'Delta-Medoids One Shot', 'Random Selection', 'Greedy Selection'],\n",
    "                       [names, names, names, names])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
